IMPORTING LIBRARIES
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score,classification_report
import os
import re
import nltk
%matplotlib inline


##IMPORTING DATASET
os.chdir('C:\\Users\\Aashi\\Downloads\\sentiment')
os.getcwd()     

train = pd.read_csv("Train.csv")
test = pd.read_csv("Test.csv")
valid = pd.read_csv("Valid.csv")


##LABELLING POSITIVE AND NEGATIVE SENTIMENTS
lst1 = []
for i in train['label']:
    if i == 0:
        lst1.append("Negative")
    else:
        lst1.append("Positive")
train['Review'] = lst1

lst2 = []
for i in test['label']:
    if i == 0:
        lst2.append("Negative")
    else:
        lst2.append("Positive")
test['Review'] = lst2


##VIEWING DATASET
train.head()

test.info()

train.info()

valid.info()


##CONCATENATE DATASET
df = pd.concat([train,test])
df.reset_index(drop=True, inplace=True)
y= df['label']


##PREPROCESSING THE DATA
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords 
# storing   dictionary words
words = set(nltk.corpus.words.words())
# Lemmatize
lemmatiser = WordNetLemmatizer()
# To remove the stop words from data for speed 
StopWords = stopwords.words("english")
def pre_process_data(data):

    remove_stop_words=False
    features = []
    
    for row in data:
        
        temp = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ',row)
        temp = re.sub("br"," ", temp)
        temp = re.sub("[^a-zA-Z]", " ", temp)
        temp = re.sub(' +', ' ', temp).lower()
        
        if remove_stop_words:
            temp = " ".join([lemmatiser.lemmatize(w) for w in temp.split(' ') if w not in StopWords])
        else:
            temp = " ".join([lemmatiser.lemmatize(w) for w in temp.split(' ')])
        
        #Excluding all non - english words
        temp = " ".join(w for w in nltk.wordpunct_tokenize(temp) if w in words or not w.isalpha())
        
        features.append(temp)
        
    features = np.array(features)
    return features
    
    features_train = pre_process_data(df['text'])
    
    
##CREATING WORDCLOUD
##importing all necessery modules 
from wordcloud import WordCloud, STOPWORDS 
import matplotlib.pyplot as plt 
import pandas as pd 
comment_words = '' 
stopwords = set(STOPWORDS) 
stopwords.add("ut")
# plot the WordCloud image
for val in features_train: 
    
   # typecaste each val to string 
    val = str(val) 

    # split the value 
    tokens = val.split() 
    
    comment_words += " ".join(tokens)+" "
wordcloud = WordCloud(width = 1300, height = 800, 
                background_color ='white', 
                stopwords = stopwords, 
                min_font_size = 10).generate(comment_words) 
plt.figure(figsize = (9,9)) 
plt.imshow(wordcloud) 
plt.axis("off") 
plt.title("WORDCLOUD",fontsize=18)
plt.show() 


from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import CountVectorizer
CV = CountVectorizer(analyzer="word", max_features=1500,max_df=0.7,min_df=0.1) 
X = CV.fit_transform(features_train)
tfi = TfidfTransformer()
X =  tfi.fit_transform(X).toarray()
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)


##USING RANDOM FOREST CLASSIFIER
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(n_estimators=100)
model.fit(X_train,y_train)
pred1 = model.predict(X_test)
print("PREDICTION: "+str(round(accuracy_score(y_test,pred1)*100,2)))

##USING NAIVE BAYES
from sklearn.naive_bayes import MultinomialNB
MNB = MultinomialNB()
MNB.fit(X_train,y_train)
pred3 = MNB.predict(X_test)
print("PREDICTION : "+str(round(accuracy_score(y_test,pred3)*100,2)))

##USING LOGISTIC REGRESSION
from sklearn.linear_model import LogisticRegression
M = LogisticRegression()
MNB.fit(X_train,y_train)
pred2 = MNB.predict(X_test)
print("PREDICTION : "+str(round(accuracy_score(y_test,pred2)*100,2)))


##CHECKING VALIDATION DATASET
## separately show accuracy for validation and Our trained model
valid_df = pd.concat([valid,test])
valid_df.reset_index(drop=True, inplace=True)
y2 = valid_df['label']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5,shuffle = False)

## USING RANDOM FOREST
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(n_estimators=100)
model.fit(X_train,y_train)
pred1 = model.predict(X_test)
print("PREDICTION: "+str(round(accuracy_score(y_test,pred1)*100,2)))

USING NAIVE BAYES
from sklearn.naive_bayes import MultinomialNB
MNB = MultinomialNB()
MNB.fit(X_train,y_train)
pred3 = MNB.predict(X_test)
print("PREDICTION : "+str(round(accuracy_score(y_test,pred3)*100,2)))

##USING LOGISTIC REGRESSION
from sklearn.linear_model import LogisticRegression
M = LogisticRegression()
MNB.fit(X_train,y_train)
pred2 = MNB.predict(X_test)
print("PREDICTION : "+str(round(accuracy_score(y_test,pred2)*100,2)))
